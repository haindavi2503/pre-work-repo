{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haindavi2503/pre-work-repo/blob/main/DL-SatelliteImagery/Satellite_Imagery_DeepLearning_ActivationHeatmap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Satellite Imagery Data Preparation\n",
        "\n"
      ],
      "metadata": {
        "id": "9rljNnL5n-lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "#from patchify import patchify\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "WYjtduool9a_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minmaxscaler = MinMaxScaler()"
      ],
      "metadata": {
        "id": "OrDufqtIl_Fj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_root_folder = '/content/drive/MyDrive/Colab Notebooks/datasets/satellite/'"
      ],
      "metadata": {
        "id": "tDKYwQVAmA8E"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"DubaiDataset/\""
      ],
      "metadata": {
        "id": "G8IWvZRRmG_9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_patch_size = 256"
      ],
      "metadata": {
        "id": "U-0NrPKxmRYf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dataset = []\n",
        "mask_dataset = []\n",
        "\n",
        "for image_type in ['images' , 'masks']:\n",
        "  if image_type == 'images':\n",
        "    image_extension = 'jpg'\n",
        "  elif image_type == 'masks':\n",
        "     image_extension = 'png'\n",
        "  for tile_id in range(1,8):\n",
        "    for image_id in range(1,20):\n",
        "      image = cv2.imread(f'{dataset_root_folder}/{dataset_name}/Tile {tile_id}/{image_type}/image_part_00{image_id}.{image_extension}',1)\n",
        "      if image is not None:\n",
        "        if image_type == 'masks':\n",
        "          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        #print(image.shape)\n",
        "        size_x = (image.shape[1]//image_patch_size)*image_patch_size\n",
        "        size_y = (image.shape[0]//image_patch_size)*image_patch_size\n",
        "        #print(\"{} --- {} - {}\".format(image.shape, size_x, size_y))\n",
        "        image = Image.fromarray(image)\n",
        "        image = image.crop((0,0, size_x, size_y))\n",
        "        #print(\"({},  {})\".format(image.size[0],image.size[1]))\n",
        "        image = np.array(image)\n",
        "        patched_images = patchify(image, (image_patch_size, image_patch_size, 3), step=image_patch_size)\n",
        "        #print(len(patched_images))\n",
        "        for i in range(patched_images.shape[0]):\n",
        "          for j in range(patched_images.shape[1]):\n",
        "            if image_type == 'images':\n",
        "              individual_patched_image = patched_images[i,j,:,:]\n",
        "              #print(individual_patched_image.shape)\n",
        "              individual_patched_image = minmaxscaler.fit_transform(individual_patched_image.reshape(-1, individual_patched_image.shape[-1])).reshape(individual_patched_image.shape)\n",
        "              individual_patched_image = individual_patched_image[0]\n",
        "              #print(individual_patched_image.shape)\n",
        "              image_dataset.append(individual_patched_image)\n",
        "            elif image_type == 'masks':\n",
        "              individual_patched_mask = patched_images[i,j,:,:]\n",
        "              individual_patched_mask = individual_patched_mask[0]\n",
        "              mask_dataset.append(individual_patched_mask)\n"
      ],
      "metadata": {
        "id": "OHvrr5JYmIra"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dataset = np.array(image_dataset)\n",
        "mask_dataset = np.array(mask_dataset)"
      ],
      "metadata": {
        "id": "kIAxnCtxne3H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_building = '#3C1098'\n",
        "class_building = class_building.lstrip('#')\n",
        "class_building = np.array(tuple(int(class_building[i:i+2], 16) for i in (0,2,4)))\n",
        "print(class_building)\n",
        "\n",
        "class_land = '#8429F6'\n",
        "class_land = class_land.lstrip('#')\n",
        "class_land = np.array(tuple(int(class_land[i:i+2], 16) for i in (0,2,4)))\n",
        "print(class_land)\n",
        "\n",
        "class_road = '#6EC1E4'\n",
        "class_road = class_road.lstrip('#')\n",
        "class_road = np.array(tuple(int(class_road[i:i+2], 16) for i in (0,2,4)))\n",
        "print(class_road)\n",
        "\n",
        "class_vegetation = '#FEDD3A'\n",
        "class_vegetation = class_vegetation.lstrip('#')\n",
        "class_vegetation = np.array(tuple(int(class_vegetation[i:i+2], 16) for i in (0,2,4)))\n",
        "print(class_vegetation)\n",
        "\n",
        "class_water = '#E2A929'\n",
        "class_water = class_water.lstrip('#')\n",
        "class_water = np.array(tuple(int(class_water[i:i+2], 16) for i in (0,2,4)))\n",
        "print(class_water)\n",
        "\n",
        "class_unlabeled = '#9B9B9B'\n",
        "class_unlabeled = class_unlabeled.lstrip('#')\n",
        "class_unlabeled = np.array(tuple(int(class_unlabeled[i:i+2], 16) for i in (0,2,4)))\n",
        "print(class_unlabeled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6_3AaG8maJA",
        "outputId": "953e67c2-c34c-4c1b-8caa-ec32ea969527"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 60  16 152]\n",
            "[132  41 246]\n",
            "[110 193 228]\n",
            "[254 221  58]\n",
            "[226 169  41]\n",
            "[155 155 155]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = individual_patched_mask"
      ],
      "metadata": {
        "id": "y89efXDBmcrP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f82ab2da-c39b-453f-a4f4-161a1d7bb516"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'individual_patched_mask' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2753415356.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindividual_patched_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'individual_patched_mask' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb_to_label(label):\n",
        "  label_segment = np.zeros(label.shape, dtype=np.uint8)\n",
        "  label_segment[np.all(label == class_water, axis=-1)] = 0\n",
        "  label_segment[np.all(label == class_land, axis=-1)] = 1\n",
        "  label_segment[np.all(label == class_road, axis=-1)] = 2\n",
        "  label_segment[np.all(label == class_building, axis=-1)] = 3\n",
        "  label_segment[np.all(label == class_vegetation, axis=-1)] = 4\n",
        "  label_segment[np.all(label == class_unlabeled, axis=-1)] = 5\n",
        "  #print(label_segment)\n",
        "  label_segment = label_segment[:,:,0]\n",
        "  #print(label_segment)\n",
        "  return label_segment"
      ],
      "metadata": {
        "id": "mZ2M23e_mdFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "for i in range(mask_dataset.shape[0]):\n",
        "  label = rgb_to_label(mask_dataset[i])\n",
        "  labels.append(label)"
      ],
      "metadata": {
        "id": "umFpRZFhme1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.array(labels)\n",
        "labels = np.expand_dims(labels, axis=3)"
      ],
      "metadata": {
        "id": "CKyKRgIcmmaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_image_id = random.randint(0, len(image_dataset))\n",
        "\n",
        "plt.figure(figsize=(14,8))\n",
        "plt.subplot(121)\n",
        "plt.imshow(image_dataset[random_image_id])\n",
        "plt.subplot(122)\n",
        "#plt.imshow(mask_dataset[random_image_id])\n",
        "plt.imshow(labels[random_image_id][:,:,0])"
      ],
      "metadata": {
        "id": "19VDRNOdmtS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "MBNS43vQmxF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_categorical_dataset = to_categorical(labels, num_classes=total_classes)"
      ],
      "metadata": {
        "id": "CqCblRNimzIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_trianing_dataset = image_dataset"
      ],
      "metadata": {
        "id": "vtDYuJI4m2NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "NapdJfgwm4ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(master_trianing_dataset, labels_categorical_dataset, test_size=0.15, random_state=100)"
      ],
      "metadata": {
        "id": "Xtm3U-UXnu6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "JhKWfLtKnwwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_height = X_train.shape[1]\n",
        "image_width = X_train.shape[2]\n",
        "image_channels = X_train.shape[3]\n",
        "total_classes = y_train.shape[3]"
      ],
      "metadata": {
        "id": "LM8L0_xnnxRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_height)\n",
        "print(image_width)\n",
        "print(image_channels)\n",
        "print(total_classes)"
      ],
      "metadata": {
        "id": "6odlwxmXuibC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_4PgoL5koHDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U segmentation-models"
      ],
      "metadata": {
        "id": "HoA-i571J8ke",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
        "from keras.layers import concatenate, BatchNormalization, Dropout, Lambda"
      ],
      "metadata": {
        "id": "hSSZ_Mh_nzFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "U-55GFbQvM6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_coef(y_true, y_pred):\n",
        "  y_true_flatten = K.flatten(y_true)\n",
        "  y_pred_flatten = K.flatten(y_pred)\n",
        "  intersection = K.sum(y_true_flatten * y_pred_flatten)\n",
        "  final_coef_value = (intersection + 1.0) / (K.sum(y_true_flatten) + K.sum(y_pred_flatten) - intersection + 1.0)\n",
        "  return final_coef_value\n"
      ],
      "metadata": {
        "id": "gZt7V6BRvgc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_unet_model(n_classes=5, image_height=256, image_width=256, image_channels=1):\n",
        "\n",
        "  inputs = Input((image_height, image_width, image_channels))\n",
        "\n",
        "  source_input = inputs\n",
        "\n",
        "  c1 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(source_input)\n",
        "  c1 = Dropout(0.2)(c1)\n",
        "  c1 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c1)\n",
        "  p1 = MaxPooling2D((2,2))(c1)\n",
        "\n",
        "  c2 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p1)\n",
        "  c2 = Dropout(0.2)(c2)\n",
        "  c2 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c2)\n",
        "  p2 = MaxPooling2D((2,2))(c2)\n",
        "\n",
        "  c3 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p2)\n",
        "  c3 = Dropout(0.2)(c3)\n",
        "  c3 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c3)\n",
        "  p3 = MaxPooling2D((2,2))(c3)\n",
        "\n",
        "  c4 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p3)\n",
        "  c4 = Dropout(0.2)(c4)\n",
        "  c4 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c4)\n",
        "  p4 = MaxPooling2D((2,2))(c4)\n",
        "\n",
        "  c5 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p4)\n",
        "  c5 = Dropout(0.2)(c5)\n",
        "  c5 = Conv2D(256, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c5)\n",
        "\n",
        "  u6 = Conv2DTranspose(128, (2,2), strides=(2,2), padding=\"same\")(c5)\n",
        "  u6 = concatenate([u6, c4])\n",
        "  c6 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u6)\n",
        "  c6 = Dropout(0.2)(c6)\n",
        "  c6 = Conv2D(128, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c6)\n",
        "\n",
        "  u7 = Conv2DTranspose(64, (2,2), strides=(2,2), padding=\"same\")(c6)\n",
        "  u7 = concatenate([u7, c3])\n",
        "  c7 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u7)\n",
        "  c7 = Dropout(0.2)(c7)\n",
        "  c7 = Conv2D(64, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c7)\n",
        "\n",
        "  u8 = Conv2DTranspose(32, (2,2), strides=(2,2), padding=\"same\")(c7)\n",
        "  u8 = concatenate([u8, c2])\n",
        "  c8 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u8)\n",
        "  c8 = Dropout(0.2)(c8)\n",
        "  c8 = Conv2D(32, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c8)\n",
        "\n",
        "  u9 = Conv2DTranspose(16, (2,2), strides=(2,2), padding=\"same\")(c8)\n",
        "  u9 = concatenate([u9, c1], axis=3)\n",
        "  c9 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u9)\n",
        "  c9 = Dropout(0.2)(c9)\n",
        "  c9 = Conv2D(16, (3,3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c9)\n",
        "\n",
        "  outputs = Conv2D(n_classes, (1,1), activation=\"softmax\")(c9)\n",
        "\n",
        "  model = Model(inputs=[inputs], outputs=[outputs])\n",
        "  return model"
      ],
      "metadata": {
        "id": "znDQ8-XdzSJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = [\"accuracy\", jaccard_coef]"
      ],
      "metadata": {
        "id": "n7QizpjF0ttw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_height)\n",
        "print(image_width)\n",
        "print(image_channels)\n",
        "print(total_classes)"
      ],
      "metadata": {
        "id": "D0Sb5QwQ_u-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_deep_learning_model():\n",
        "  return multi_unet_model(n_classes=total_classes,\n",
        "                          image_height=image_height,\n",
        "                          image_width=image_width,\n",
        "                          image_channels=image_channels)"
      ],
      "metadata": {
        "id": "3WunBOZE_Ywt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_deep_learning_model()"
      ],
      "metadata": {
        "id": "B5Oz4Taw_wyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Please uncomment this line to get model confiuration\n",
        "# model.get_config()"
      ],
      "metadata": {
        "id": "C4giCd_gDE9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Loss Function\n",
        "\n",
        "- dice loss > Focal Loss > Total Loss\n",
        "- Total Loss = (Dice loss + (1*Focal Loss))"
      ],
      "metadata": {
        "id": "zfdq2xYuJlbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = [0.1666, 0.1666, 0.1666, 0.1666, 0.1666, 0.1666]"
      ],
      "metadata": {
        "id": "3s-t3D5sDzyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models as sm"
      ],
      "metadata": {
        "id": "KuNQYaoAJtor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dice_loss = sm.losses.DiceLoss(class_weights = weights)"
      ],
      "metadata": {
        "id": "Gfu3Rjp5J6ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "focal_loss = sm.losses.CategoricalFocalLoss()"
      ],
      "metadata": {
        "id": "WrsYeLxfKf0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_loss = dice_loss + (1 * focal_loss)"
      ],
      "metadata": {
        "id": "DBrhramWKlOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model compilation"
      ],
      "metadata": {
        "id": "ep1H-tHhKx5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "JOURkXveKo8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n"
      ],
      "metadata": {
        "id": "tE9Q9e3ZK1qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss=total_loss, metrics=metrics)"
      ],
      "metadata": {
        "id": "syAax956K6Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "7pZM2YOBLJQ_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history = model.fit(X_train, y_train,\n",
        "                          batch_size=16,\n",
        "                          verbose=1,\n",
        "                          epochs=100,\n",
        "                          validation_data=(X_test, y_test),\n",
        "                          shuffle=False)"
      ],
      "metadata": {
        "id": "2OZCtKpQvDpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history_a.history['loss']\n",
        "val_loss = history_a.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'r', label=\"Validation Loss\")\n",
        "plt.title(\"Training Vs Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KIiv1RKvQkLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jaccard_coef = history_a.history['jaccard_coef']\n",
        "val_jaccard_coef = history_a.history['val_jaccard_coef']\n",
        "\n",
        "epochs = range(1, len(jaccard_coef) + 1)\n",
        "plt.plot(epochs, jaccard_coef, 'y', label=\"Training IoU\")\n",
        "plt.plot(epochs, val_jaccard_coef, 'r', label=\"Validation IoU\")\n",
        "plt.title(\"Training Vs Validation IoU\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "AI_eBr2qQokL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing prediction results\n",
        "-  using test images using mask images and predicted result images.."
      ],
      "metadata": {
        "id": "TNA6h3yMf14-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "_QN1MPq5hzGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_number = random.randint(0, len(X_test))\n",
        "\n",
        "test_image = X_test[test_image_number]\n",
        "ground_truth_image = y_test_argmax[test_image_number]\n",
        "\n",
        "test_image_input = np.expand_dims(test_image, 0)\n",
        "\n",
        "prediction = saved_model.predict(test_image_input)\n",
        "#prediction = model.predict(test_image_input)\n",
        "predicted_image = np.argmax(prediction, axis=3)\n",
        "predicted_image = predicted_image[0,:,:]"
      ],
      "metadata": {
        "id": "-Hatz2tbfpwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,8))\n",
        "plt.subplot(231)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(test_image)\n",
        "plt.subplot(232)\n",
        "plt.title(\"Original Masked image\")\n",
        "plt.imshow(ground_truth_image)\n",
        "plt.subplot(233)\n",
        "plt.title(\"Predicted Image\")\n",
        "plt.imshow(predicted_image)\n"
      ],
      "metadata": {
        "id": "uZZOrT0KhQWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model saving and reloading (with custom loss and custom metrics)\n",
        "\n",
        "- loss\n",
        "  - 'dice_loss_plus_1focal_loss': total_loss\n",
        "- Metrics\n",
        "  - jaccard_coef: jaccard_coef"
      ],
      "metadata": {
        "id": "pBFoIPWQhd16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model.get_config()"
      ],
      "metadata": {
        "id": "OBGQg_H9i_Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('satellite-imagery.h5')"
      ],
      "metadata": {
        "id": "CmtF2FDKmF0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lah"
      ],
      "metadata": {
        "id": "b2yYvns3mWYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "ssw1oJ8vmYey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model = load_model('/content/satellite-imagery.h5',\n",
        "                         custom_objects=({'dice_loss_plus_1focal_loss': total_loss,\n",
        "                                          'jaccard_coef': jaccard_coef}))"
      ],
      "metadata": {
        "id": "r1Xnfjb0mgqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model.loss.name"
      ],
      "metadata": {
        "id": "oMFMoyc3qT-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saved_model.get_config()"
      ],
      "metadata": {
        "id": "W0_4dEafq9G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performing Prediction using the custom image from Google Map"
      ],
      "metadata": {
        "id": "hOxkOhdzsXTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(Image.open('/content/fc-img1.jpg'))"
      ],
      "metadata": {
        "id": "m4gdGA_ZrqO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(Image.open('/content/fc-img2.jpg'))"
      ],
      "metadata": {
        "id": "-smjVNcEsxde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open('/content/fc-img1.jpg')\n",
        "image = image.resize((256,256))\n",
        "image = np.array(image)\n",
        "image = np.expand_dims(image, 0)"
      ],
      "metadata": {
        "id": "FH-z9tyXszvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = saved_model.predict(image)"
      ],
      "metadata": {
        "id": "KBjZ2TPKtJ9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_image = np.argmax(prediction, axis=3)\n",
        "predicted_image = predicted_image[0,:,:]"
      ],
      "metadata": {
        "id": "VOBK13JYt6Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,8))\n",
        "plt.subplot(231)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(Image.open('/content/fc-img1.jpg'))\n",
        "plt.subplot(232)\n",
        "plt.title(\"Predicted Image\")\n",
        "plt.imshow(predicted_image)"
      ],
      "metadata": {
        "id": "UoxgPzumt_Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collecting Activation and gradients output from Keras Model"
      ],
      "metadata": {
        "id": "D5oHk426z0Fa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keract"
      ],
      "metadata": {
        "id": "OcbAqqvauIZ6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keract as ke"
      ],
      "metadata": {
        "id": "CTHpQUCez-F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activations = ke.get_activations(saved_model, image, nodes_to_evaluate=None, output_format='simple', auto_compile=True)"
      ],
      "metadata": {
        "id": "TYJEvZg30LHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls -lah /content/activations"
      ],
      "metadata": {
        "id": "Xe4d7V0v0w4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(Image.open('/content/activations/0_input_1.png'))"
      ],
      "metadata": {
        "id": "M9VBmmIl0oj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(Image.open('/content/activations/1_conv2d.png'))"
      ],
      "metadata": {
        "id": "CJAHaSD02J2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(Image.open('/content/activations/40_conv2d_18.png'))"
      ],
      "metadata": {
        "id": "xTa94vjM2OMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(Image.open('/content/heatmap/0_input_1.png'))"
      ],
      "metadata": {
        "id": "nzfKVF2L7650"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(Image.open('/content/heatmap/40_conv2d_18.png'))"
      ],
      "metadata": {
        "id": "jdPt-A1L3n9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(Image.open('/content/heatmap/4_max_pooling2d.png'))"
      ],
      "metadata": {
        "id": "OcsHm7cU5wka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(Image.open('/content/heatmap/8_max_pooling2d_1.png'))"
      ],
      "metadata": {
        "id": "ebwDBHwB8Typ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(Image.open('/content/heatmap/12_max_pooling2d_2.png'))"
      ],
      "metadata": {
        "id": "dR7KGtuz8YC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(Image.open('/content/heatmap/16_max_pooling2d_3.png'))"
      ],
      "metadata": {
        "id": "-SzQSL3z8dXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iDfhkh8_8ffw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}